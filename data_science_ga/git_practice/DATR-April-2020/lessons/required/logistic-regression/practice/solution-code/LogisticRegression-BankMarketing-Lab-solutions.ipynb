{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "\n",
    "# Logistic Regresion Lab\n",
    "## Exercise with bank marketing data\n",
    "\n",
    "_Authors: Sam Stack(DC)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction\n",
    "- Data from the UCI Machine Learning Repository: data, [data dictionary](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing)\n",
    "- **Goal**: Predict whether a customer will purchase a bank product marketed over the phone\n",
    "- `bank-additional.csv` is already in our repo, so there is no need to download the data from the UCI website\n",
    "\n",
    "## Step 1: Read the data into Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>1.313</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>services</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.855</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>wed</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.962</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.959</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>4.191</td>\n",
       "      <td>5195.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital          education default  housing     loan  \\\n",
       "0   30  blue-collar  married           basic.9y      no      yes       no   \n",
       "1   39     services   single        high.school      no       no       no   \n",
       "2   25     services  married        high.school      no      yes       no   \n",
       "3   38     services  married           basic.9y      no  unknown  unknown   \n",
       "4   47       admin.  married  university.degree      no      yes       no   \n",
       "\n",
       "     contact month day_of_week  ...  campaign  pdays  previous     poutcome  \\\n",
       "0   cellular   may         fri  ...         2    999         0  nonexistent   \n",
       "1  telephone   may         fri  ...         4    999         0  nonexistent   \n",
       "2  telephone   jun         wed  ...         1    999         0  nonexistent   \n",
       "3  telephone   jun         fri  ...         3    999         0  nonexistent   \n",
       "4   cellular   nov         mon  ...         1    999         0  nonexistent   \n",
       "\n",
       "  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed  y  \n",
       "0         -1.8          92.893          -46.2      1.313       5099.1  0  \n",
       "1          1.1          93.994          -36.4      4.855       5191.0  0  \n",
       "2          1.4          94.465          -41.8      4.962       5228.1  0  \n",
       "3          1.4          94.465          -41.8      4.959       5228.1  0  \n",
       "4         -0.1          93.200          -42.0      4.191       5195.8  0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "bank = pd.read_csv('../../data/bank.csv')\n",
    "bank.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**  Target '`y`' represented as such**\n",
    "    - No : 0\n",
    "    - Yes : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3668\n",
       "1     451\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the results of y\n",
    "bank['y'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 2: Prepare at least three features\n",
    "- Include both numeric and categorical features\n",
    "- Choose features that you think might be related to the response (based on intuition or exploration)\n",
    "- Think about how to handle missing values (encoded as \"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Im going to take about 6 features and build two separate models.  \n",
    "# Age, Job, Marital, education, contact, day of week.\n",
    "# A correlation matrix or heat map is probably beneficial to finding useful features.\n",
    "# This can be difficult with the amount of categorical features in the data.\n",
    "# Once converted to dummie variables that will still be a computationally expensive process\n",
    "# to compare all features.\n",
    "\n",
    "# there was no formal eda behind my selection, I just wanted to use random features.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admin.           1012\n",
      "blue-collar       884\n",
      "technician        691\n",
      "services          393\n",
      "management        324\n",
      "retired           166\n",
      "self-employed     159\n",
      "entrepreneur      148\n",
      "unemployed        111\n",
      "housemaid         110\n",
      "student            82\n",
      "unknown            39\n",
      "Name: job, dtype: int64\n",
      "married     2509\n",
      "single      1153\n",
      "divorced     446\n",
      "unknown       11\n",
      "Name: marital, dtype: int64\n",
      "university.degree      1264\n",
      "high.school             921\n",
      "basic.9y                574\n",
      "professional.course     535\n",
      "basic.4y                429\n",
      "basic.6y                228\n",
      "unknown                 167\n",
      "illiterate                1\n",
      "Name: education, dtype: int64\n",
      "cellular     2652\n",
      "telephone    1467\n",
      "Name: contact, dtype: int64\n",
      "thu    860\n",
      "mon    855\n",
      "tue    841\n",
      "wed    795\n",
      "fri    768\n",
      "Name: day_of_week, dtype: int64\n",
      "0    3668\n",
      "1     451\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "features = ['age','job','marital','education','contact','day_of_week','y']\n",
    "\n",
    "for feat in features:\n",
    "    if feat != 'age':\n",
    "        print(bank[feat].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Qualitative data analysis**  \n",
    "So I have some unknown values in `education`, `marital` and `employment`.  We could make assumptions that the 39 unkown from `employment` are most likely in `admin` professions or that the 11 unknown in `marital` are most likely `married` (unfortunate that they are uncertain about it).\n",
    "\n",
    "Personally, im going to drop the unknowns as I do not want to encorporate any addition bias into the data itself.  \n",
    "- Going forward a more sound method of replacing unknowns is to build models to predict them using K Nearest neighbors, that way you are filling in an unknown using the most similar observations you have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the sub dataframe with only the features im using\n",
    "bank_a =  bank[features]\n",
    "\n",
    "# getting rid of unknowns\n",
    "bank_a = bank_a[bank_a['education'] != 'unknown']\n",
    "bank_a = bank_a[bank_a['job'] != 'unknown']\n",
    "bank_a = bank_a[bank_a['marital'] != 'unknown']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My data is read to get dummied, but i'll wait until im about to model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 3: Model building\n",
    "- Use cross-validation to evaluate the logistic regression model with your chosen features.  \n",
    "    You can use any (combination) of the following metrics to evaluate.\n",
    "    - [Classification/Accuracy Error](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
    "    - [Confusion Matrix](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)\n",
    "    - [ROC curves and area under a curve (AUC)](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score)\n",
    "    - [Log loss](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html)\n",
    "- Try to increase the AUC by selecting different sets of features\n",
    "    - *Bonus*: Experiment with hyper parameters such are regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build a Model**  \n",
    "*Model 1, using `age`, `job`, `education`, and `day_of_week`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jake\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# md = ModelData.  Dummies ignores numeric columns such as age and y\n",
    "bank_md1 = pd.get_dummies(bank_a[['age','job','education','day_of_week','y']], drop_first = True)\n",
    "\n",
    "\n",
    "bank\n",
    "# no hyper parameters for first model\n",
    "LogReg1 = LogisticRegression()\n",
    "\n",
    "# X and y features\n",
    "X1 = bank_md1.drop('y', axis =1)\n",
    "y1 = bank_md1['y']\n",
    "\n",
    "\n",
    "\n",
    "# using train test split to cross val\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(X1,y1, random_state =42)\n",
    "\n",
    "# fit model\n",
    "LogReg1.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the Coefficient for each feature.**\n",
    "- Be sure to make note of interesting findings.\n",
    "\n",
    "*Seems like `job_entrepreneur` carries that largest coef.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>0.00762961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>job_blue-collar</td>\n",
       "      <td>-0.426391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>job_entrepreneur</td>\n",
       "      <td>-1.49324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>job_housemaid</td>\n",
       "      <td>-0.444983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>job_management</td>\n",
       "      <td>-0.426168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>job_retired</td>\n",
       "      <td>0.608415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>job_self-employed</td>\n",
       "      <td>-0.330618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>job_services</td>\n",
       "      <td>-0.405957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>job_student</td>\n",
       "      <td>0.904477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>job_technician</td>\n",
       "      <td>-0.0304069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>job_unemployed</td>\n",
       "      <td>0.185178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>education_basic.6y</td>\n",
       "      <td>-0.40132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>education_basic.9y</td>\n",
       "      <td>-0.249878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>education_high.school</td>\n",
       "      <td>0.0198983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>education_illiterate</td>\n",
       "      <td>-0.0862204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>education_professional.course</td>\n",
       "      <td>0.0584506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>education_university.degree</td>\n",
       "      <td>0.302194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>day_of_week_mon</td>\n",
       "      <td>0.0200679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>day_of_week_thu</td>\n",
       "      <td>-0.0142871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>day_of_week_tue</td>\n",
       "      <td>-0.0473691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>day_of_week_wed</td>\n",
       "      <td>-0.21958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Name        Coef\n",
       "0                             age  0.00762961\n",
       "1                 job_blue-collar   -0.426391\n",
       "2                job_entrepreneur    -1.49324\n",
       "3                   job_housemaid   -0.444983\n",
       "4                  job_management   -0.426168\n",
       "5                     job_retired    0.608415\n",
       "6               job_self-employed   -0.330618\n",
       "7                    job_services   -0.405957\n",
       "8                     job_student    0.904477\n",
       "9                  job_technician  -0.0304069\n",
       "10                 job_unemployed    0.185178\n",
       "11             education_basic.6y    -0.40132\n",
       "12             education_basic.9y   -0.249878\n",
       "13          education_high.school   0.0198983\n",
       "14           education_illiterate  -0.0862204\n",
       "15  education_professional.course   0.0584506\n",
       "16    education_university.degree    0.302194\n",
       "17                day_of_week_mon   0.0200679\n",
       "18                day_of_week_thu  -0.0142871\n",
       "19                day_of_week_tue  -0.0473691\n",
       "20                day_of_week_wed    -0.21958"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = bank_md1.columns.drop('y')\n",
    "\n",
    "coef = LogReg1.coef_[0]\n",
    "\n",
    "pd.DataFrame([name,coef],index = ['Name','Coef']).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the Model to predict on x_test and evaluate the model using metric(s) of Choice.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict with model\n",
    "y_pred = LogReg1.predict(x_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Accuracy Score**\n",
    "\n",
    "- Wow thats a pretty good score wouldn't you say?  Almost 90!  Remember the distribution of classes though.  In our entire dataset there are 3668 \"No\" and 451 \"Yes\" and a total of 4119 observations.  If we guessed that nobody was going to convert and therefore 'No' every time, we would be correct 89% of the time (according to out data).  That being said, this accuracy is barely better than baseline and such an insignificant difference could just be from how our train test split groupped the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.898876404494382"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test1,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**\n",
    "\n",
    "Looks like we have 880 True Negatives and 99 False Negatives.  That being said it looks like all our model is doing is predicting 'no' everytime.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[880,   0],\n",
       "       [ 99,   0]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test1,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ROC AUC**\n",
    "\n",
    "The Area Under the ROC Curve is 0.5 which is completely wothless and our model gains no more insight that random guessing.  If we go back to the Accuracy score, we can now conclude that its minuscule improvement above the baseline is caused by our train test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_test1,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Log Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.492685253417935"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.log_loss(y_test1,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Using `age`, `job`, `marital`, `education`, `contact` and `day_of_week` to predict If the bought or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jake\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# md = ModelData.  Dummies ignores numeric columns such as age and y\n",
    "bank_md2 = pd.get_dummies(bank_a, drop_first = True)\n",
    "\n",
    "# no hyper parameters for first model\n",
    "LogReg2 = LogisticRegression()\n",
    "\n",
    "# X and y features\n",
    "X2 = bank_md2.drop('y', axis =1)\n",
    "y2 = bank_md2['y']\n",
    "\n",
    "# using train test split to cross val\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(X2,y2, random_state =42)\n",
    "\n",
    "# fit model\n",
    "LogReg2.fit(x_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = LogReg2.predict(x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.898876404494382"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test2,y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[880,   0],\n",
       "       [ 99,   0]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test2,y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_test2,y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.492685253417935"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.log_loss(y_test2,y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the metrics really changed.  Looks like the features we have arn't very helpful...\n",
    "\n",
    "\n",
    "### Is your model not performing very well?\n",
    "\n",
    "Lets try one more thing before we revert to grabbing more features.  Adjusting the probability threshold.\n",
    "\n",
    "Use the `LogisticRegression.predict_proba()` attribute to get the probabilities.\n",
    "\n",
    "Recall from the lesson the first probability is the for class 0 and the second is for class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8158757 , 0.1841243 ],\n",
       "       [0.93530948, 0.06469052],\n",
       "       [0.817475  , 0.182525  ],\n",
       "       ...,\n",
       "       [0.8269768 , 0.1730232 ],\n",
       "       [0.95319974, 0.04680026],\n",
       "       [0.89820994, 0.10179006]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob = LogReg2.predict_proba(x_test2)\n",
    "\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([193., 187., 165., 173., 153.,  65.,  22.,   8.,   8.,   5.]),\n",
       " array([0.00949688, 0.04323104, 0.0769652 , 0.11069936, 0.14443352,\n",
       "        0.17816768, 0.21190184, 0.245636  , 0.27937016, 0.31310432,\n",
       "        0.34683848]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_prob_t = y_pred_prob.transpose()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(y_pred_prob_t[0])\n",
    "plt.show()\n",
    "plt.hist(y_pred_prob_t[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Calculate a new threshold and use it to convert predicted probabilities to output classes**\n",
    "\n",
    "Lets try decreaseing the threshold to %20 predicted probability or higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "979\n",
      "979\n"
     ]
    }
   ],
   "source": [
    "y_pred3=[]\n",
    "for prob in y_pred_prob_t[1]:\n",
    "    if prob > .20:\n",
    "        y_pred3.append(1)\n",
    "    else:\n",
    "        y_pred3.append(0)\n",
    "        \n",
    "print(len(y_pred3))\n",
    "print(len(y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred3.count(1)  #Actually made some predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate the model metrics now**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8610827374872319"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test2,y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[834,  46],\n",
       "       [ 90,   9]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test2,y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5193181818181818"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_test2,y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.798069837783086"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.log_loss(y_test2,y_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Build a model using all of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_all = pd.get_dummies(bank, drop_first = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jake\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\jake\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l1', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no hyper parameters for first model\n",
    "LogReg3 = LogisticRegression(penalty='l1',C=0.01)\n",
    "\n",
    "# X and y features\n",
    "X3 = bank_all.drop('y', axis =1)\n",
    "y3 = bank_all['y']\n",
    "\n",
    "# using train test split to cross val\n",
    "x_train3, x_test3, y_train3, y_test3 = train_test_split(X3,y3, random_state =42)\n",
    "\n",
    "# fit model\n",
    "LogReg3.fit(x_train3, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = LogReg3.predict(x_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[895,  26],\n",
       "       [ 68,  41]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test3, y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6739583022044248"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_test3, y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Use Regularization to optimize your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jake\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\jake\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\jake\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6739583022044248  :  0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jake\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\jake\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6820468378009543  :  0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jake\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\jake\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\jake\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6936367530307106  :  1.0\n",
      "0.6941796411957486  :  10\n",
      "0.6947225293607866  :  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jake\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# X and y features\n",
    "X = bank_all.drop('y', axis =1)\n",
    "y = bank_all['y']\n",
    "\n",
    "# using train test split to cross val\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, random_state =42)\n",
    "\n",
    "cees = [0.01, 0.1, 1.0, 10, 100]\n",
    "\n",
    "for c in cees:\n",
    "    logreg = LogisticRegression(penalty='l1', C=c)\n",
    "    logreg.fit(x_train,y_train)\n",
    "    y_pred = logreg.predict(x_test)\n",
    "    roc = metrics.roc_auc_score(y_test, y_pred)\n",
    "    print(roc,\" : \", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jake\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\jake\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\jake\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6982239089940133  :  1.1\n",
      "0.6976810208289753  :  1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jake\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6976810208289753  :  1.3\n",
      "0.6965952444988993  :  1.4\n",
      "0.6965952444988993  :  1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jake\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\jake\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\jake\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6976810208289753  :  1.6\n",
      "0.6971381326639373  :  1.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jake\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\jake\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6976810208289753  :  1.8\n",
      "0.6971381326639373  :  1.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jake\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cees = [1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7 ,1.8, 1.9]\n",
    "\n",
    "for c in cees:\n",
    "    logreg = LogisticRegression(penalty='l1', C=c)\n",
    "    logreg.fit(x_train,y_train)\n",
    "    y_pred = logreg.predict(x_test)\n",
    "    roc = metrics.roc_auc_score(y_test, y_pred)\n",
    "    print(roc,\" : \", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
