{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Homework 4 NLP Exercises\n",
    "\n",
    "_Authors: Dave Yerrington (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "In this lab we will further explore sklearn and NLTK's capabilities for processing text. We will use the 20 Newsgroup dataset, which is provided by sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Data Science Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting that SKLearn Dataset\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Use the `fetch_20newsgroups` function to download a training and testing set.\n",
    "\n",
    "Look up the function documentation for how to grab the data.\n",
    "\n",
    "You should pull these categories:\n",
    "- `alt.atheism`\n",
    "- `talk.religion.misc`\n",
    "- `comp.graphics`\n",
    "- `sci.space`\n",
    "\n",
    "Also remove the headers, footers, and quotes using the `remove` keyword argument of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism',\n",
      " 'comp.graphics',\n",
      " 'comp.os.ms-windows.misc',\n",
      " 'comp.sys.ibm.pc.hardware',\n",
      " 'comp.sys.mac.hardware',\n",
      " 'comp.windows.x',\n",
      " 'misc.forsale',\n",
      " 'rec.autos',\n",
      " 'rec.motorcycles',\n",
      " 'rec.sport.baseball',\n",
      " 'rec.sport.hockey',\n",
      " 'sci.crypt',\n",
      " 'sci.electronics',\n",
      " 'sci.med',\n",
      " 'sci.space',\n",
      " 'soc.religion.christian',\n",
      " 'talk.politics.guns',\n",
      " 'talk.politics.mideast',\n",
      " 'talk.politics.misc',\n",
      " 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "# A:\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "from pprint import pprint\n",
    "pprint(list(newsgroups_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats = ['alt.atheism','talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=cats, remove=('headers', 'footers', 'quotes'))\n",
    "list(newsgroups_train.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.filenames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, 0, 2, 0, 2, 1, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1353,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=cats, remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test.filenames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, 1, 1, 1, 2, 2, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_test.target[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data inspection\n",
    "\n",
    "We have downloaded a few newsgroup categories and removed headers, footers and quotes.\n",
    "\n",
    "Because this is an sklearn dataset, it comes with pre-split train and test sets (note we were able to call 'train' and 'test' in subset).\n",
    "\n",
    "Let's inspect them.\n",
    "\n",
    "1. What data taype is `data_train`\n",
    "- Is it like a list? Or like a Dictionary? or what?\n",
    "- How many data points does it contain?\n",
    "- Inspect the first data point, what does it look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n",
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A:\n",
    "# A: looks like a dictionary, 2034 data points in the data list\n",
    "print(type(newsgroups_train))\n",
    "print(type(newsgroups_train['data']))\n",
    "print(type(newsgroups_train['target']))\n",
    "newsgroups_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n"
     ]
    }
   ],
   "source": [
    "# looks like a document of an email or letter\n",
    "print(newsgroups_train['data'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bag of Words model\n",
    "\n",
    "Let's train a model using a simple count vectorizer.\n",
    "\n",
    "1. Initialize a standard CountVectorizer and fit the training data\n",
    "- how big is the feature dictionary?\n",
    "- repeat eliminating english stop words\n",
    "- is the dictionary smaller?\n",
    "- transform the training data using the trained vectorizer\n",
    "- evaluate the performance of a Logistic Regression on the features extracted by the CountVectorizer\n",
    "    - you will have to transform the test_set too. Be carefule to use the trained vectorizer, without re-fitting it\n",
    "\n",
    "**BONUS:**\n",
    "- try a couple modifications:\n",
    "    - restrict the max_features\n",
    "    - change max_df and min_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 26879)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A: 26879 features\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "vect = CountVectorizer()\n",
    "newsgroups_train_dtm = vect.fit_transform(newsgroups_train.data)\n",
    "newsgroups_train_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 26576)\n",
      "(1353, 26576)\n"
     ]
    }
   ],
   "source": [
    "# english stopping elimination did not delete too many features, the document number is slightly smaller\n",
    "vect1 = CountVectorizer(stop_words='english')\n",
    "newsgroups_train_dtm1 = vect1.fit_transform(newsgroups_train.data)\n",
    "newsgroups_test_dtm1 = vect1.transform(newsgroups_test.data)\n",
    "print(newsgroups_train_dtm1.shape)\n",
    "print(newsgroups_test_dtm1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = newsgroups_train_dtm1\n",
    "y_train = newsgroups_train.target\n",
    "X_test  = newsgroups_test_dtm1\n",
    "y_test  = newsgroups_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7420546932742055\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "logreg = LogisticRegression(C=1e9)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "print((metrics.accuracy_score(y_test, y_pred_class)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 11620)\n",
      "(1353, 11620)\n"
     ]
    }
   ],
   "source": [
    "vect2 = CountVectorizer(stop_words='english', min_df=2, max_df=40, max_features=15000)\n",
    "newsgroups_train_dtm2 = vect2.fit_transform(newsgroups_train.data)\n",
    "newsgroups_test_dtm2 = vect2.transform(newsgroups_test.data)\n",
    "print(newsgroups_train_dtm2.shape)\n",
    "print(newsgroups_test_dtm2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7287509238728751\n"
     ]
    }
   ],
   "source": [
    "X_train = newsgroups_train_dtm2\n",
    "X_test  = newsgroups_test_dtm2\n",
    "logreg = LogisticRegression(C=1e9)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "print((metrics.accuracy_score(y_test, y_pred_class)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Hashing and TF-IDF\n",
    "\n",
    "Let's see if Hashing or TF-IDF improves the accuracy.\n",
    "\n",
    "1. Initialize a HashingVectorizer and repeat the test with no restriction on the number of features\n",
    "- does the score improve with respect to the count vectorizer?\n",
    "- print out the number of features for this model\n",
    "- Initialize a TF-IDF Vectorizer and repeat the analysis above\n",
    "- print out the number of features for this model\n",
    "\n",
    "**BONUS:**\n",
    "- Change the parameters of either (or both!) models to improve your score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 1048576)\n",
      "(1353, 1048576)\n"
     ]
    }
   ],
   "source": [
    "# A: 1048576 features!\n",
    "vect3 = HashingVectorizer(stop_words='english')\n",
    "newsgroups_train_dtm3 = vect3.fit_transform(newsgroups_train.data)\n",
    "newsgroups_test_dtm3 = vect3.transform(newsgroups_test.data)\n",
    "print(newsgroups_train_dtm3.shape)\n",
    "print(newsgroups_test_dtm3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7435328898743533\n"
     ]
    }
   ],
   "source": [
    "X_train = newsgroups_train_dtm3\n",
    "X_test  = newsgroups_test_dtm3\n",
    "logreg = LogisticRegression(C=1e9)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "print((metrics.accuracy_score(y_test, y_pred_class)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HashingVectorizer increased features dramtically but only sightly improved score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 26576)\n",
      "(1353, 26576)\n"
     ]
    }
   ],
   "source": [
    "vect4 = TfidfVectorizer(stop_words='english')\n",
    "newsgroups_train_dtm4 = vect4.fit_transform(newsgroups_train.data)\n",
    "newsgroups_test_dtm4 = vect4.transform(newsgroups_test.data)\n",
    "print(newsgroups_train_dtm4.shape)\n",
    "print(newsgroups_test_dtm4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7583148558758315\n"
     ]
    }
   ],
   "source": [
    "X_train = newsgroups_train_dtm4\n",
    "X_test  = newsgroups_test_dtm4\n",
    "logreg = LogisticRegression(C=1e9)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "print((metrics.accuracy_score(y_test, y_pred_class)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TfidfVectorizer has the same features as the CountVectorizer and improved score bigger than that of the HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 11882)\n",
      "(1353, 11882)\n"
     ]
    }
   ],
   "source": [
    "vect5 = TfidfVectorizer(stop_words='english', min_df=2, max_df=60, max_features=20000)\n",
    "newsgroups_train_dtm5 = vect5.fit_transform(newsgroups_train.data)\n",
    "newsgroups_test_dtm5 = vect5.transform(newsgroups_test.data)\n",
    "print(newsgroups_train_dtm5.shape)\n",
    "print(newsgroups_test_dtm5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7634885439763488\n"
     ]
    }
   ],
   "source": [
    "X_train = newsgroups_train_dtm5\n",
    "X_test  = newsgroups_test_dtm5\n",
    "logreg = LogisticRegression(C=1e9)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "print((metrics.accuracy_score(y_test, y_pred_class)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TfidfVectorizer can improve score from its default by adjusting max_features, min_df, max_df, etc. parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Airline Tweets Sentiment Analysis Lab\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are going to be analyzing tweets about airlines.  These have been hand-tagged with sentiment.  There are three categories: positive, neutral, and negative.\n",
    "\n",
    "Use VADER to calculate sentiment for each tweet, and see if you can correctly predict the hand-tagged sentiment.\n",
    "\n",
    "What is the accuracy?  Print out a heatmap to see where your model performs well, and where it performs poorly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, \\\n",
    "precision_score, recall_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"data/Tweets.csv\", encoding= 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment         airline  \\\n",
       "0           neutral  Virgin America   \n",
       "1          positive  Virgin America   \n",
       "2           neutral  Virgin America   \n",
       "3          negative  Virgin America   \n",
       "4          negative  Virgin America   \n",
       "\n",
       "                                                text  \n",
       "0                @VirginAmerica What @dhepburn said.  \n",
       "1  @VirginAmerica plus you've added commercials t...  \n",
       "2  @VirginAmerica I didn't today... Must mean I n...  \n",
       "3  @VirginAmerica it's really aggressive to blast...  \n",
       "4  @VirginAmerica and it's a really big bad thing...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   airline_sentiment  14640 non-null  object\n",
      " 1   airline            14640 non-null  object\n",
      " 2   text               14640 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 343.2+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preview the airline_sentiment column.\n",
    "- What percentage of reviews are positive, neutral, and negative?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    9178\n",
       "neutral     3099\n",
       "positive    2363\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A:\n",
    "tweets['airline_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6269125683060109 0.21168032786885246 0.16140710382513662\n"
     ]
    }
   ],
   "source": [
    "neg_counts = tweets['airline_sentiment'].value_counts()['negative']\n",
    "neu_counts = tweets['airline_sentiment'].value_counts()['neutral']\n",
    "pos_counts = tweets['airline_sentiment'].value_counts()['positive']\n",
    "neg_rev = neg_counts/(neg_counts+neu_counts+pos_counts)\n",
    "neu_rev = neu_counts/(neg_counts+neu_counts+pos_counts)\n",
    "pos_rev = pos_counts/(neg_counts+neu_counts+pos_counts)\n",
    "print(neg_rev, neu_rev, pos_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels to numerics\n",
    "def sent_digit(senti_string):\n",
    "    if 'negative' in senti_string:\n",
    "        return 0\n",
    "    elif 'neutral' in senti_string:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline</th>\n",
       "      <th>text</th>\n",
       "      <th>senti_dig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment         airline  \\\n",
       "0           neutral  Virgin America   \n",
       "1          positive  Virgin America   \n",
       "2           neutral  Virgin America   \n",
       "3          negative  Virgin America   \n",
       "4          negative  Virgin America   \n",
       "\n",
       "                                                text  senti_dig  \n",
       "0                @VirginAmerica What @dhepburn said.          1  \n",
       "1  @VirginAmerica plus you've added commercials t...          2  \n",
       "2  @VirginAmerica I didn't today... Must mean I n...          1  \n",
       "3  @VirginAmerica it's really aggressive to blast...          0  \n",
       "4  @VirginAmerica and it's a really big bad thing...          0  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new column of digitized sentiment\n",
    "tweets['senti_dig'] = tweets.apply(lambda x: sent_digit(x['airline_sentiment']), axis=1)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load in the Sentiment IntensityAnalyzer from Vader and add compound, negative, neutral, and positive scores into the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.104, 'neu': 0.767, 'pos': 0.129, 'compound': 1.0}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A: Test the water a little first, typical score output is a dictionary of 4 key-value pairs\n",
    "analyser.polarity_scores(tweets.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline</th>\n",
       "      <th>text</th>\n",
       "      <th>senti_dig</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.129</td>\n",
       "      <td>-0.2716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment         airline  \\\n",
       "0           neutral  Virgin America   \n",
       "1          positive  Virgin America   \n",
       "2           neutral  Virgin America   \n",
       "3          negative  Virgin America   \n",
       "4          negative  Virgin America   \n",
       "\n",
       "                                                text  senti_dig    neg    neu  \\\n",
       "0                @VirginAmerica What @dhepburn said.          1  0.000  1.000   \n",
       "1  @VirginAmerica plus you've added commercials t...          2  0.000  1.000   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...          1  0.000  1.000   \n",
       "3  @VirginAmerica it's really aggressive to blast...          0  0.226  0.645   \n",
       "4  @VirginAmerica and it's a really big bad thing...          0  0.296  0.704   \n",
       "\n",
       "     pos  compound  \n",
       "0  0.000    0.0000  \n",
       "1  0.000    0.0000  \n",
       "2  0.000    0.0000  \n",
       "3  0.129   -0.2716  \n",
       "4  0.000   -0.5829  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A: Now do the real work here\n",
    "tweets_senti = tweets.join(tweets['text'].apply(lambda x: analyser.polarity_scores(x)).apply(pd.Series))\n",
    "tweets_senti.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Store airline_sentiment in y to use as labels and create an appropriate feature matrix, X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14640,) (14640, 4)\n"
     ]
    }
   ],
   "source": [
    "# A:\n",
    "y = tweets_senti.senti_dig\n",
    "X = tweets_senti.loc[:, ['neg', 'neu', 'pos', 'compound']].copy()\n",
    "print(y.shape, X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fit a model of your choice to predict airline_sentient and cross-validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5974726775956285\n",
      "0.6910519125683059\n"
     ]
    }
   ],
   "source": [
    "# A: Try logistic regression first\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "kf = model_selection.KFold(n_splits=10, shuffle=True, random_state=99)\n",
    "logreg = LogisticRegression(C=1e9)\n",
    "print(np.mean(-cross_val_score(logreg, X, y, cv=kf, scoring='neg_mean_squared_error')))\n",
    "print(np.mean(cross_val_score(logreg, X, y, cv=kf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A: try knn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.585792349726776\n",
      "0.6752732240437159\n"
     ]
    }
   ],
   "source": [
    "# A:\n",
    "print(np.mean(-cross_val_score(knn, X, y, cv=kf, scoring='neg_mean_squared_error')))\n",
    "print(np.mean(cross_val_score(knn, X, y, cv=kf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Display the confusion matrix.\n",
    "- What reviews are difficult to identify?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6983606557377049\n"
     ]
    }
   ],
   "source": [
    "# A: We take a standard train_test_split for a logistic regression model as an example to evaluate\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 99)\n",
    "model = logreg.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2180,   11,   90],\n",
       "       [ 623,   22,  123],\n",
       "       [ 247,   10,  354]], dtype=int64)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=[0, 1, 2])\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the Confusion matrix above, neutral reviews are most difficult to identify, there are large number of false negatives on this label where they were either predited as negative or positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08147056, 0.34712104, 0.15802593, 0.36369791, 0.36369791,\n",
       "       0.20437465, 0.0226712 , 0.01624505, 0.36369791, 0.21165627,\n",
       "       0.02540004, 0.20054031, 0.1135957 , 0.00853652, 0.15236124,\n",
       "       0.31391391, 0.14649024, 0.09802228, 0.27284963, 0.19618892])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get probability predictions.\n",
    "model_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "model_pred_proba[20:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Print the classification report and discuss the characteristics of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6169068765586747"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A:\n",
    "precision_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5212483589987945"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A:\n",
    "recall_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.96      0.82      2281\n",
      "           1       0.51      0.03      0.05       768\n",
      "           2       0.62      0.58      0.60       611\n",
      "\n",
      "    accuracy                           0.70      3660\n",
      "   macro avg       0.62      0.52      0.49      3660\n",
      "weighted avg       0.66      0.70      0.62      3660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "relatively negative sentiment was better predicted by the model and it is got the best scores. The postive sentiment was predicted not so well with large false negatives classified to negatives. The neutral sentiment was worst predicted with large false negatives classified to both positives and negatives. The accuracy score of close to 70% was just slightly better than the baseline accuracy."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
